# pip install torch
# pip install torchvision
# pip install opencv-python matplotlib
# pip install 'git+https://github.com/facebookresearch/segment-anything.git'
import numpy as np
import torch
import matplotlib.pyplot as plt
import cv2

import sys
sys.path.append("..")  # Adjust path if needed
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor


def preprocess_image(image):
    """
    Preprocesses an image for use with the Sam model.

    This function assumes the model expects RGB images in a specific range.
    Adapt this function based on your model's requirements.

    Args:
        image: A NumPy array representing the image (BGR format).

    Returns:
        A NumPy array representing the preprocessed image (RGB format).
    """

    # Convert BGR to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Normalize pixel values (typical range: 0.0 to 1.0)
    image = image.astype(np.float32) / 255.0

    # ... (Additional preprocessing steps as needed by your model)

    return image


def generate_masks_from_tensor(frame_tensor):
    """
    Generates masks using SamAutomaticMaskGenerator from a given frame_tensor.

    Args:
        frame_tensor: A torch.Tensor representing the image.

    Returns:
        A list of masks generated by the model.
    """

    # Ensure tensor is on the correct device
    frame_tensor = frame_tensor.to(device)

    # Convert tensor to NumPy array if needed
    image = frame_tensor.numpy()

    # Preprocess image (adapt based on your model)
    image = preprocess_image(image)

    masks = mask_generator_.generate(image)

    return masks


def show_anns(anns, image):
    """
    Visualizes annotations (masks) on the image.

    Args:
        anns: A list of masks (dictionaries with segmentation, area, etc.).
        image: A NumPy array representing the image.
    """

    if len(anns) == 0:
        return

    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.random.random((1, 3)).tolist()[0]
        overlay = np.dstack((color_mask, m * 0.35))  # Transparency for visualization
        ax.imshow(overlay)

    plt.imshow(image)
    plt.axis('off')
    plt.show()


# Model parameters (replace with your choices and ensure ethical considerations)
sam_checkpoint = "sam_vit_h_4b8939.pth"  # Replace with your pre-trained model path
model_type = "vit_h"  # Replace with the corresponding model type
device = "cuda" if torch.cuda.is_available() else "cpu"  # Use GPU if available

# Load Sam model (replace with appropriate model loading logic)
sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)

# Mask generation configuration (adjust parameters as needed)
mask_generator_ = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=32,
    pred_iou_thresh=0.9,
    stability_score_thresh=0.96,
    crop_n_layers=1,
    crop_n_points_downscale_factor=2,
    min_mask_region_area=100,  # Requires open-cv to run post-processing
)


# Example usage:
# You can now replace the image loading part with your logic for obtaining the frame_tensor
# from your video processing pipeline.
# frame_tensor = ...  # Your frame_tensor logic here

# Generate masks
masks = generate_masks_from_tensor(frame_tensor)

# Visualize results (optional)
show_anns(masks, image)  # Replace 'image' with your original image if needed
